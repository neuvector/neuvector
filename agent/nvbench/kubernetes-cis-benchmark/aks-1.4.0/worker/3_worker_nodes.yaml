version: aks-1.4.0
id: 3
title: 3 - Worker Nodes
type: node
groups:
  - id: 3.1
    title: 3.1 Worker Node Configuration Files
    checks:
      - id: K.3.1.1
        description: Ensure that the kubeconfig file permissions are set to 644 or
          more restrictive (Manual)
        type: worker
        category: kubernetes
        scored: false
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          file="/var/lib/kubelet/kubeconfig"
          file=$(append_prefix "$CONFIG_PREFIX" "$file")
          if [ -e "$file" ]; then
            if [ "$(stat -c %a $file)" -eq 644 -o "$(stat -c %a $file)" -eq 600 -o "$(stat -c %a $file)" -eq 400 ]; then
              pass "$check"
              pass "      * read check_argument for $file"
            else
              warn "$check"
              warn "      * Wrong permissions for $file"
            fi
          else
            warn "$check"
            warn "      * The kubeconfig service file, $file not found"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the each worker node. For example, chmod 644 /proc/1/root/var/lib/kubelet/kubeconfig
      - id: K.3.1.2
        description: Ensure that the kubelet kubeconfig file ownership is set to root:root
          (Manual)
        type: worker
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if [ -e "$file" ]; then
            if [ "$(stat -c %u%g $file)" -eq 00 ]; then
              pass "$check"
            else
              warn "$check"
              warn "      * Wrong ownership for $file"
            fi
          else
            warn "$check"
            warn "      * The kubeconfig service file, $file not found"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the each worker node. For example, chown root:root /proc/1/root/var/lib/kubelet/kubeconfig
      - id: K.3.1.3
        description: Ensure that the kubelet configuration file has permissions set
          to 644 or more restrictive (Manual)
        type: worker
        category: kubernetes
        scored: true
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          file=""
          file="/etc/kubernetes/kubelet/kubelet-config.json"
          file=$(append_prefix "$CONFIG_PREFIX" "$file")
          if [ -e "$file" ]; then
            if [ "$(stat -c %a $file)" -eq 644 -o "$(stat -c %a $file)" -eq 600 -o "$(stat -c %a $file)" -eq 400 ]; then
              pass "$check"
              pass "      * read check_argument for $file"
            else
              warn "$check"
              warn "      * Wrong permissions for $file"
            fi
          else
            warn "$check"
            warn "      * kubelet configuration file, $file not found"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the each worker node. For example, chmod chmod 644 /proc/1/root/etc/kubernetes/kubelet/kubelet-config.json
      - id: K.3.1.4
        description: Ensure that the kubelet configuration file ownership is set to
          root:root (Manual)
        type: worker
        category: kubernetes
        scored: true
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if [ -e "$file" ]; then
            if [ "$(stat -c %u%g $file)" -eq 00 ]; then
              pass "$check"
            else
              warn "$check"
              warn "      * Wrong ownership for $file"
            fi
          else
            warn "$check"
            warn "      * kubelet configuration file, $file not found"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the each worker node. For example, chown root:root /proc/1/root/etc/kubernetes/kubelet/kubelet-config.json
  - id: 3.2
    title: 3.2 - Kubelet
    checks:
      - id: K.3.2.1
        description: Ensure that the --anonymous-auth argument is set to false (Automated)
        type: worker
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument "$CIS_KUBELET_CMD" '--anonymous-auth=false' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          Remediation Method 1:
          If modifying the Kubelet config file, edit the kubelet-config.json file /etc/kubernetes/kubelet/kubelet-config.json and set the below parameter to false
          "anonymous": "enabled": false
          Remediation Method 2:
          If using executable arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubelet-args.conf on each worker node and add the below parameter at the end of the KUBELET_ARGS variable string.
          --anonymous-auth=false
          Remediation Method 3:
          If using the api configz endpoint consider searching for the status of "authentication.*anonymous":{"enabled":false}" by extracting the live configuration from the nodes running kubelet.
          **See detailed step-by-step configmap procedures in Reconfigure a Node's Kubelet in a Live Cluster, and then rerun the curl statement from audit process to check for kubelet configuration changes
          kubectl proxy --port=8001 &
          export HOSTNAME_PORT=localhost:8001 (example host and port number)
          export NODE_NAME=ip-192.168.31.226.aks.internal (example node name from
          "kubectl get nodes")
          curl -sSL "http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz"
          Based on your system, restart the kubelet service. For example:
          systemctl daemon-reload
          systemctl restart kubelet.service
          systemctl status kubelet -l
      - id: K.3.2.2
        description: Ensure that the --authorization-mode argument is not set to AlwaysAllow
          (Automated)
        type: worker
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument "$CIS_KUBELET_CMD" '--authorization-mode=AlwaysAllow' >/dev/null 2>&1; then
              warn "$check"
          else
              pass "$check"
          fi
        remediation: |
          If using a Kubelet config file, edit the file to set authorization: mode to Webhook.
          If using executable arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_AUTHZ_ARGS variable.
          --authorization-mode=Webhook
          Based on your system, restart the kubelet service. For example:
          systemctl daemon-reload
          systemctl restart kubelet.service
      - id: K.3.2.3
        description: Ensure that the --client-ca-file argument is set as appropriate
          (Automated)
        type: worker
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument "$CIS_KUBELET_CMD" '--client-ca-file' >/dev/null 2>&1; then
              cafile=$(get_argument_value "$CIS_KUBELET_CMD" '--client-ca-file')
              cafile=$(append_prefix "$CONFIG_PREFIX" "$cafile")
              pass "$check"
              pass "      * client-ca-file: $cafile"
          else
              warn "$check"
          fi
        remediation: |
          If using a Kubelet config file, edit the file to set authentication: x509: clientCAFile to the location of the client CA file.
          If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_AUTHZ_ARGS variable.
          --client-ca-file=<path/to/client-ca-file>
          Based on your system, restart the kubelet service. For example:
          systemctl daemon-reload
          systemctl restart kubelet.service
      - id: K.3.2.4
        description: Ensure that the --read-only-port is secured (Manual)
        type: worker
        category: kubernetes
        scored: true
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument "$CIS_KUBELET_CMD" '--read-only-port' >/dev/null 2>&1; then
              port=$(get_argument_value "$CIS_KUBELET_CMD" '--read-only-port' | cut -d "=" -f 2)
              if [ $port = "0" ]; then
                  pass "$check"
              else
                  warn "$check"
                  warn "      * read-only-port: $port"
              fi
          else
              warn "$check"
          fi
        remediation: |
          If using a Kubelet config file, edit the file to set readOnlyPort to 0.
          If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.
          --read-only-port=0
          Based on your system, restart the kubelet service. For example:
          systemctl daemon-reload
          systemctl restart kubelet.service
      - id: K.3.2.5
        description: Ensure that the --streaming-connection-idle-timeout argument
          is not set to 0 (Automated)
        type: worker
        category: kubernetes
        scored: true
        profile: Level 1
        automated: false
        tags: {}
        audit: |
          check="$id  - $description"
          if check_argument "$CIS_KUBELET_CMD" '--streaming-connection-idle-timeout=0' >/dev/null 2>&1; then
              timeout=$(get_argument_value "$CIS_KUBELET_CMD" '--streaming-connection-idle-timeout')
              warn "$check"
              warn "      * streaming-connection-idle-timeout: $timeout"
          else
              pass "$check"
          fi
        remediation: |
          If using a Kubelet config file, edit the file to set streamingConnectionIdleTimeout to a value other than 0.
          If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.
          --streaming-connection-idle-timeout=5m
          Based on your system, restart the kubelet service. For example:
          systemctl daemon-reload
          systemctl restart kubelet.service
      - id: K.3.2.6
        description: Ensure that the --make-iptables-util-chains argument is set to
          true (Automated)
        type: worker
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags: {}
        audit: |
          check="$id  - $description"
          if check_argument "$CIS_KUBELET_CMD" '--make-iptables-util-chains=true' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          If using a Kubelet config file, edit the file to set makeIPTablesUtilChains: true.
          If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and remove the --mak-iptables-util-chains argument from the KUBELET_SYSTEM_PODS_ARGS variable.
          Based on your system, restart the kubelet service. For example:
          systemctl daemon-reload
          systemctl restart kubelet.service
      - id: K.3.2.7
        description: Ensure that the --hostname-override argument is not set (Manual)
        type: worker
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags: {}
        audit: |
          check="$id  - $description"
          if check_argument "$CIS_KUBELET_CMD" '--hostname-override' >/dev/null 2>&1; then
              warn "$check"
          else
              pass "$check"
          fi
        remediation: 'Edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
          on each worker node and remove the --hostname-override argument from the
          KUBELET_SYSTEM_PODS_ARGS variable. Based on your system, restart the kubelet
          service. For example:  systemctl daemon-reload systemctl restart kubelet.service'
      - id: K.3.2.8
        description: Ensure that the --eventRecordQPS argument is set to 0 or a level
          which ensures appropriate event capture (Automated)
        type: worker
        category: kubernetes
        scored: false
        profile: Level 2
        automated: false
        tags: {}
        audit: |
          check="$id  - $description"
          if check_argument "$CIS_KUBELET_CMD" '--event-qps' >/dev/null 2>&1; then
              qps=$(get_argument_value "$CIS_KUBELET_CMD" '--event-qps' | cut -d " " -f 1)
              if [ "$qps" -gt 0 ]; then
                  pass "$check"
              else
                  warn "$check"
                  warn "      * --event-qps: $qps is not set to a positive value"
              fi
          else
              warn "$check"
              warn "      * --event-qps is not set"
          fi
        remediation: |
          Remediation Method 1:
          If modifying the Kubelet config file, edit the kubelet-config.json file /etc/kubernetes/kubelet/kubelet-config.json and set the below parameter to 5 or a value greater or equal to 0
          "eventRecordQPS": 5
          Check that /etc/systemd/system/kubelet.service.d/10-kubelet-args.conf does not define an executable argument for eventRecordQPS because this would override your Kubelet config.
          Remediation Method 2:
          If using executable arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubelet-args.conf on each worker node and add the below parameter at the end of the KUBELET_ARGS variable string.
          --eventRecordQPS=5
          Remediation Method 3:
          If using the api configz endpoint consider searching for the status of "eventRecordQPS" by extracting the live configuration from the nodes running kubelet.
          **See detailed step-by-step configmap procedures in Reconfigure a Node's Kubelet in a Live Cluster, and then rerun the curl statement from audit process to check for kubelet configuration changes
          kubectl proxy --port=8001 &
          export HOSTNAME_PORT=localhost:8001 (example host and port number)
          export NODE_NAME=ip-192.168.31.226.aks.internal (example node name from
          "kubectl get nodes")
          curl -sSL "http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz"
          kubectl proxy --port=8001 &
          export HOSTNAME_PORT=localhost:8001 (example host and port number)
          export NODE_NAME=ip-192.168.31.226.aks.internal (example node name from
          "kubectl get nodes")
          curl -sSL "http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz"
          For all three remediations:
          Based on your system, restart the kubelet service and check status
          systemctl daemon-reload
          systemctl restart kubelet.service
          systemctl status kubelet -l
      - id: K.3.2.9
        description: Ensure that the --rotate-certificates argument is not set to
          false (Automated)
        type: worker
        category: kubernetes
        scored: true
        profile: Level 2
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument "$CIS_KUBELET_CMD" '--rotate-certificates=false' >/dev/null 2>&1; then
            warn "$check"
          else
            pass "$check"
          fi
        remediation: |
          If using a Kubelet config file, edit the file to add the line rotateCertificates: true or remove it altogether to use the default value.
          If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and remove --rotate-certificates=false argument from the KUBELET_CERTIFICATE_ARGS variable.
          Based on your system, restart the kubelet service. For example:
          systemctl daemon-reload
          systemctl restart kubelet.service
      - id: K.3.2.10
        description: Ensure that the RotateKubeletServerCertificate argument is set
          to true (Automated)
        type: worker
        category: kubernetes
        scored: true
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          file=""
          if check_argument "$CIS_KUBELET_CMD" '--config' >/dev/null 2>&1; then
              file=$(get_argument_value "$CIS_KUBELET_CMD" '--config'|cut -d " " -f 1)
          fi
          file=$(append_prefix "$CONFIG_PREFIX" "$file")
          if [ -e "$file" ]; then
            found=$(sed -rn '/--feature-gates=RotateKubeletServerCertificate=true/p' $file)
            if [ -z "$found" ]; then
                warn "$check"
                warn "      * --feature-gates=RotateKubeletServerCertificate=true not found"
            else
                pass "$check"
            fi
          else
            warn "$check"
            warn "      * The kubeconfig service file not found"
          fi
        remediation: |-
          Edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_CERTIFICATE_ARGS variable.
          --feature-gates=RotateKubeletServerCertificate=true
          Based on your system, restart the kubelet service. For example:
          systemctl daemon-reload
          systemctl restart kubelet.service
