version: cis-k3s-1.8
id: 1
title: 1 - Control Plane Components
type: master
groups:
  - id: 1.1
    title: 1.1 - Control Plane Node Configuration Files
    checks:
      - id: K.1.1.1
        description: Ensure that the API server pod specification file permissions
          are set to 600 or more restrictive (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          pass "$check"
        remediation: By default, K3s embeds the api server within the k3s process. There is no API server pod specification file.
      - id: K.1.1.2
        description: Ensure that the API server pod specification file ownership is
          set to root:root (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          pass "$check"
        remediation: By default, K3s embeds the api server within the k3s process. There is no API server pod specification file.
      - id: K.1.1.3
        description: Ensure that the controller manager pod specification file permissions
          are set to 600 or more restrictive (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          pass "$check"
        remediation: By default, K3s embeds the controller manager within the k3s process. There is no controller manager pod specification file.
      - id: K.1.1.4
        description: Ensure that the controller manager pod specification file ownership
          is set to root:root (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          pass "$check"
        remediation: By default, K3s embeds the controller manager within the k3s process. There is no controller manager pod specification file.
      - id: K.1.1.5
        description: Ensure that the scheduler pod specification file permissions
          are set to 600 or more restrictive (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          pass "$check"
        remediation: By default, K3s embeds the scheduler within the k3s process. There is no scheduler pod specification file.
      - id: K.1.1.6
        description: Ensure that the scheduler pod specification file ownership is
          set to root:root (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          pass "$check"
        remediation: By default, K3s embeds the scheduler within the k3s process. There is no scheduler pod specification file.
      - id: K.1.1.7
        description: Ensure that the etcd pod specification file permissions are set
          to 600 or more restrictive (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          pass "$check"
        remediation: By default, K3s embeds etcd within the k3s process. There is no etcd pod specification file.
      - id: K.1.1.8
        description: Ensure that the etcd pod specification file ownership is set
          to root:root (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          pass "$check"
        remediation: By default, K3s embeds etcd within the k3s process. There is no etcd pod specification file.
      - id: K.1.1.9
        description: Ensure that the Container Network Interface file permissions
          are set to 600 or more restrictive (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          dir=$(append_prefix "$CONFIG_PREFIX" "/var/lib/cni/networks")
          all_pass=true
          fail_files=""

          if [ -d "$dir" ]; then
            files=$(find "$dir" -type f ! -name lock 2>/dev/null)

            if [ -z "$files" ]; then
              warn "$check"
              warn "      * No files found in $dir."
              all_pass=false
            else
              echo "$files" | while read -r file; do
                perm=$(stat -c %a "$file")
                if [ "$perm" -ne 600 ] && [ "$perm" -ne 400 ]; then
                  all_pass=false
                  fail_files="$fail_files\n      * Wrong permissions for $file (got $perm)"
                fi
              done
            fi
          else
            warn "$check"
            warn "      * CNI data directory $dir not found."
            all_pass=false
          fi

          if [ "$all_pass" = true ]; then
            pass "$check"
          else
            warn "$check"
            warn "      * One or more files failed the permission check, $fail_files"
          fi
        remediation: By default, K3s sets the CNI file permissions to 600. Note that for many CNIs, a lock file is created with permissions 750. This is expected and can be ignored. If you modify your CNI configuration, ensure that the permissions are set to 600. For example, chmod 600 /var/lib/cni/networks/<filename>
      - id: K.1.1.10
        description: Ensure that the Container Network Interface file ownership is
          set to root:root (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          dir=$(append_prefix "$CONFIG_PREFIX" "/var/lib/cni/networks")
          all_pass=true
          fail_files=""

          if [ -d "$dir" ]; then
            files=$(find "$dir" -type f ! -name lock 2>/dev/null)

            if [ -z "$files" ]; then
              warn "$check"
              warn "      * No files found in $dir."
              all_pass=false
            else
              echo "$files" | while read -r file; do
                ownership=$(stat -c %u%g "$file")
                if [ "$ownership" -ne 00 ]; then
                  all_pass=false
                  fail_files="$fail_files\n      * Wrong ownership for $file (got $perm)"
                fi
              done
            fi
          else
            warn "$check"
            warn "      * CNI data directory $dir not found."
            all_pass=false
          fi

          if [ "$all_pass" = true ]; then
            pass "$check"
          else
            warn "$check"
            warn "      * One or more files failed the ownership check, $fail_files"
          fi
        remediation: Run the below command (based on the file location on your system) on the control plane node. For example, chown root:root <path/to/cni/files>
      - id: K.1.1.11
        description: Ensure that the etcd data directory permissions are set to 700
          or more restrictive (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          dir=$(append_prefix "$CONFIG_PREFIX" "/var/lib/rancher/k3s/server/db/etcd")
          if [ -n "$ETCD_CMD" ]; then
            if [ -d "$dir" ]; then
              if [ "$(stat -c %a $dir)" -eq 700 -o "$(stat -c %a $dir)" -eq 600 -o "$(stat -c %a $dir)" -eq 400 ]; then
                pass "$check"
              else
                warn "$check"
                warn "      * Wrong permissions for $dir, get $(stat -c %a $dir)"
              fi
            else
              warn "$check"
              warn "      * etcd data directory $dir not found."
            fi
          else
            pass "$check"
          fi
        remediation: 'On the etcd server node, get the etcd data directory, passed
          as an argument --data-dir, from the below command: ps -ef | grep etcd Run
          the below command (based on the etcd data directory found above). For example,
          chmod 700 /var/lib/rancher/k3s/server/db/etcd'
      - id: K.1.1.12
        description: Ensure that the etcd data directory ownership is set to etcd:etcd
          (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          pass "$check"
        remediation: For K3s, etcd is embedded within the k3s process. There is no separate etcd process. Therefore the etcd data directory ownership is managed by the k3s process and should be root:root.
      - id: K.1.1.13
        description: Ensure that the admin.conf file permissions are set to 600 (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          file="/var/lib/rancher/k3s/server/cred/admin.kubeconfig"
          file=$(append_prefix "$CONFIG_PREFIX" "$file")

          if [ -e "$file" ]; then
            if [ "$(stat -c %a $file)" -eq 600 -o "$(stat -c %a $file)" -eq 400 ]; then
              pass "$check"
            else
              warn "$check"
              warn "      * Wrong permissions for $file, get $(stat -c %a $file)"
            fi
          else
            warn "$check"
            warn "      * File: $file not found"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the master node. For example, chmod 600 /var/lib/rancher/k3s/server/cred/admin.kubeconfig
      - id: K.1.1.14
        description: Ensure that the admin.conf file ownership is set to root:root
          (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if [ -e "$file" ]; then
            if [ "$(stat -c %u%g $file)" -eq 00 ]; then
              pass "$check"
            else
              warn "$check"
              warn "      * Wrong ownership for $file, expect root:root, get $(stat -c %U:%G $file)"
            fi
          else
            warn "$check"
            warn "      * File: $file not found"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the master node. For example, chown root:root /var/lib/rancher/k3s/server/cred/admin.kubeconfig
      - id: K.1.1.15
        description: Ensure that the scheduler.conf file permissions are set to 600
          or more restrictive (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          file="/var/lib/rancher/k3s/server/cred/scheduler.kubeconfig"
          file=$(append_prefix "$CONFIG_PREFIX" "$file")

          if [ -e "$file" ]; then
            if [ "$(stat -c %a $file)" -eq 600 -o "$(stat -c %a $file)" -eq 400 ]; then
              pass "$check"
            else
              warn "$check"
              warn "      * Wrong permissions for $file, get $(stat -c %a $file)"
            fi
          else
            warn "$check"
            warn "      * File: $file not found"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the master node. For example, chmod 600 /var/lib/rancher/k3s/server/cred/scheduler.kubeconfig
      - id: K.1.1.16
        description: Ensure that the scheduler.conf file ownership is set to root:root
          (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if [ -e "$file" ]; then
            if [ "$(stat -c %u%g $file)" -eq 00 ]; then
              pass "$check"
            else
              warn "$check"
              warn "      * Wrong ownership for $file, expect root:root, get $(stat -c %U:%G $file)"
            fi
          else
            warn "$check"
            warn "      * File: $file not found"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the master node. For example, chown root:root /var/lib/rancher/k3s/server/cred/scheduler.kubeconfig
      - id: K.1.1.17
        description: Ensure that the controller-manager.conf file permissions are
          set to 600 or more restrictive (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          file="/var/lib/rancher/k3s/server/cred/controller.kubeconfig"
          file=$(append_prefix "$CONFIG_PREFIX" "$file")

          if [ -e "$file" ]; then
            if [ "$(stat -c %a $file)" -eq 600 -o "$(stat -c %a $file)" -eq 400 ]; then
              pass "$check"
            else
              warn "$check"
              warn "      * Wrong permissions for $file, get $(stat -c %a $file)"
            fi
          else
            warn "$check"
            warn "      * File: $file not found"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the master node. For example, chmod 600 /var/lib/rancher/k3s/server/cred/controller.kubeconfig
      - id: K.1.1.18
        description: Ensure that the controller-manager.conf file ownership is set
          to root:root (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if [ -e "$file" ]; then
            if [ "$(stat -c %u%g $file)" -eq 00 ]; then
              pass "$check"
            else
              warn "$check"
              warn "      * Wrong ownership for $file, expect root:root, get $(stat -c %U:%G $file)"
            fi
          else
            warn "$check"
            warn "      * File: $file not found"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the master node. For example, chown root:root /var/lib/rancher/k3s/server/cred/controller.kubeconfig
      - id: K.1.1.19
        description: Ensure that the Kubernetes PKI directory and file ownership is
          set to root:root (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          file="/var/lib/rancher/k3s/server/tls"
          file=$(append_prefix "$CONFIG_PREFIX" "$file")
          files=$(find $file)
          pass=true
          incorrect_files=""
          for f in ${files}; do
            ownership=$(stat -c %u%g $f)
            if ! [ "$ownership" -eq 00 ]; then
              pass=false
              incorrect_files="$incorrect_files $f (ownership=$ownership)"
            fi
          done

          if [ "$pass" = "true" ]; then
            pass "$check"
          else
            warn "$check"
            warn "      * Wrong ownership for the following files: $incorrect_files"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the master node. For example, chown -R root:root /var/lib/rancher/k3s/server/tls
      - id: K.1.1.20
        description: Ensure that the Kubernetes PKI certificate file permissions are
          set to 600 or more restrictive (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          files=$(find $file -name "*.crt")
          pass=true
          incorrect_files=""
          for f in ${files}; do
            permissions=$(stat -c %a "$f")
            if ! [ "$permissions" -eq 600 ] && ! [ "$permissions" -eq 400 ]; then
              pass=false
              incorrect_files="$incorrect_files $f (permissions=$permissions)"
            fi
          done

          if [ "$pass" = "true" ]; then
            pass "$check"
          else
            warn "$check"
            warn "      * Wrong permissions for the following files: $incorrect_files"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the master node. For example, chmod -R 600 /var/lib/rancher/k3s/server/tls/*.crt
      - id: K.1.1.21
        description: Ensure that the Kubernetes PKI key file permissions are set to
          600 (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          files=$(find $file -name "*.key")
          pass=true
          incorrect_files=""
          for f in ${files}; do
            permissions=$(stat -c %a "$f")
            if ! [ "$permissions" -eq 600 ] && ! [ "$permissions" -eq 400 ]; then
              pass=false
              incorrect_files="$incorrect_files $f (permissions=$permissions)"
            fi
          done

          if [ "$pass" = "true" ]; then
            pass "$check"
          else
            warn "$check"
            warn "      * Wrong permissions for the following files: $incorrect_files"
          fi
        remediation: Run the below command (based on the file location on your system)
          on the master node. For example, chmod -R 600 /var/lib/rancher/k3s/server/tls/*.key
  - id: 1.2
    title: 1.2 - API Server
    checks:
      - id: K.1.2.1
        description: Ensure that the --anonymous-auth argument is set to false (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--anonymous-auth=false' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
              warn "      * found: $(check_argument_from_journal "$KUBE_APISERVER_CMD" '--anonymous-auth=false')"
          fi
        remediation: |
          By default, K3s sets the --anonymous-auth argument to false. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove anything similar to below.
            kube-apiserver-arg:
              - "anonymous-auth=true"
      - id: K.1.2.2
        description: Ensure that the --token-auth-file parameter is not set (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--token-auth-file' >/dev/null 2>&1; then
              warn "$check"
              warn "      * found: $(check_argument_from_journal "$KUBE_APISERVER_CMD" '--token-auth-file')"
          else
              pass "$check"
          fi
        remediation: |
          Follow the documentation and configure alternate mechanisms for authentication. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove anything similar to below.
          kube-apiserver-arg:
            - "token-auth-file=<path>"
      - id: K.1.2.3
        description: Ensure that the DenyServiceExternalIPs is set (Manual)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--disable-admission-plugins=DenyServiceExternalIP' >/dev/null 2>&1; then
              pass "$check"
          elif check_argument_from_journal "$KUBE_APISERVER_CMD" '--enable-admission-plugins=DenyServiceExternalIP' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s does not set DenyServiceExternalIPs. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml, remove any lines like below.
          kube-apiserver-arg:
            - "enable-admission-plugins=DenyServiceExternalIPs"
      - id: K.1.2.4
        description: Ensure that the --kubelet-client-certificate and --kubelet-client-key
          arguments are set as appropriate (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--kubelet-client-certificate' >/dev/null 2>&1; then
              if check_argument_from_journal "$KUBE_APISERVER_CMD" '--kubelet-client-key' >/dev/null 2>&1; then
                  certificate=$(get_argument_value_from_journal_from_journal "$KUBE_APISERVER_CMD" '--kubelet-client-certificate')
                  key=$(get_argument_value_from_journal_from_journal "$KUBE_APISERVER_CMD" '--kubelet-client-key')
                  pass "$check"
                  pass "      * kubelet-client-certificate: $certificate"
                  pass "      * kubelet-client-key: $key"
              else
                  warn "$check"
              fi
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s automatically provides the kubelet client certificate and key. They are generated and located at /var/lib/rancher/k3s/server/tls/client-kube-apiserver.crt and /var/lib/rancher/k3s/server/tls/client-kube-apiserver.key If for some reason you need to provide your own certificate and key, you can set the below parameters in the K3s config file /etc/rancher/k3s/config.yaml.
          kube-apiserver-arg:
            - "kubelet-client-certificate=<path/to/client-cert-file>"
            - "kubelet-client-key=<path/to/client-key-file>"
      - id: K.1.2.5
        description: Ensure that the --kubelet-certificate-authority argument is set
          as appropriate (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--kubelet-certificate-authority' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s automatically provides the kubelet CA cert file, at /var/lib/rancher/k3s/server/tls/server-ca.crt. If for some reason you need to provide your own ca certificate, look at using the k3s certificate command line tool. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-apiserver-arg:
            - "kubelet-certificate-authority=<path/to/ca-cert-file>"
      - id: K.1.2.6
        description: Ensure that the --authorization-mode argument is not set to AlwaysAllow
          (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--authorization-mode'| grep 'AlwaysAllow' >/dev/null 2>&1; then
              warn "$check"
          else
              pass "$check"
          fi
        remediation: |
          By default, K3s does not set the --authorization-mode to AlwaysAllow. If this check fails, edit K3s config file /etc/rancher/k3s/config.yaml, remove any lines like below.
          kube-apiserver-arg:
            - "authorization-mode=AlwaysAllow"
      - id: K.1.2.7
        description: Ensure that the --authorization-mode argument includes Node (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--authorization-mode'| grep 'Node' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: By default, K3s sets the --authorization-mode to Node and RBAC. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml, ensure that you are not overriding authorization-mode.
      - id: K.1.2.8
        description: Ensure that the --authorization-mode argument includes RBAC (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--authorization-mode'| grep 'RBAC' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: By default, K3s sets the --authorization-mode to Node and RBAC. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml, ensure that you are not overriding authorization-mode.
      - id: K.1.2.9
        description: Ensure that the admission control plugin EventRateLimit is set
          (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--enable-admission-plugins'| grep 'EventRateLimit' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          Follow the Kubernetes documentation and set the desired limits in a configuration file. Then, edit the K3s config file /etc/rancher/k3s/config.yaml and set the below parameters.
          kube-apiserver-arg:
            - "enable-admission-plugins=...,EventRateLimit,..."
            - "admission-control-config-file=<path/to/configuration/file>"
      - id: K.1.2.10
        description: Ensure that the admission control plugin AlwaysAdmit is not set
          (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--enable-admission-plugins'| grep 'AlwaysAdmit' >/dev/null 2>&1; then
              warn "$check"
          else
              pass "$check"
          fi
        remediation: |
          By default, K3s does not set the --enable-admission-plugins to AlwaysAdmit. If this check fails, edit K3s config file /etc/rancher/k3s/config.yaml, remove any lines like below.
          kube-apiserver-arg:
            - "enable-admission-plugins=AlwaysAdmit"
      - id: K.1.2.11
        description: Ensure that the admission control plugin AlwaysPullImages is
          set (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--enable-admission-plugins'| grep 'AlwaysPullImages' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          Permissive, per CIS guidelines, "This setting could impact offline or isolated clusters, which have images pre-loaded and do not have access to a registry to pull in-use images. This setting is not appropriate for clusters which use this configuration." Edit the K3s config file /etc/rancher/k3s/config.yaml and set the below parameter.
          kube-apiserver-arg:
            - "enable-admission-plugins=...,AlwaysPullImages,..."
      - id: K.1.2.12
        description: Ensure that the admission control plugin SecurityContextDeny
          is set if PodSecurityPolicy is not used (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
        audit: |
          check="$id  - $description"
          pass "$check"
        remediation: Enabling Pod Security Policy is no longer supported on K3s v1.25+ and will cause applications to unexpectedly fail.
      - id: K.1.2.13
        description: Ensure that the admission control plugin ServiceAccount is set
          (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--disable-admission-plugins'| grep 'ServiceAccount' >/dev/null 2>&1; then
              warn "$check"
          else
              pass "$check"
          fi
        remediation: |
          By default, K3s does not set the --disable-admission-plugins to anything. Follow the documentation and create ServiceAccount objects as per your environment. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-apiserver-arg:
            - "disable-admission-plugins=ServiceAccount"
      - id: K.1.2.14
        description: Ensure that the admission control plugin NamespaceLifecycle is
          set (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--disable-admission-plugins'| grep 'NamespaceLifecycle' >/dev/null 2>&1; then
              warn "$check"
          else
              pass "$check"
          fi
        remediation: |
          By default, K3s does not set the --disable-admission-plugins to anything. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-apiserver-arg:
            - "disable-admission-plugins=...,NamespaceLifecycle,..."
      - id: K.1.2.15
        description: Ensure that the admission control plugin NodeRestriction is set
          (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--enable-admission-plugins'| grep 'NodeRestriction' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s sets the --enable-admission-plugins to NodeRestriction. If using the K3s config file /etc/rancher/k3s/config.yaml, check that you are not overriding the admission plugins. If you are, include NodeRestriction in the list.
          kube-apiserver-arg:
            - "enable-admission-plugins=...,NodeRestriction,..."
      - id: K.1.2.16
        description: Ensure that the --profiling argument is set to false (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags: {}
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--profiling=false' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s sets the --profiling argument to false. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-apiserver-arg:
            - "profiling=true"
      - id: K.1.2.17
        description: Ensure that the --audit-log-path argument is set (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--audit-log-path' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          Edit the K3s config file /etc/rancher/k3s/config.yaml and set the audit-log-path parameter to a suitable path and file where you would like audit logs to be written, for example,
          kube-apiserver-arg:
            - "audit-log-path=/var/lib/rancher/k3s/server/logs/audit.log"
      - id: K.1.2.18
        description: Ensure that the --audit-log-maxage argument is set to 30 or as
          appropriate (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--audit-log-maxage' >/dev/null 2>&1; then
              maxage=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--audit-log-maxage'|cut -d " " -f 1)
              if [ "$maxage" -ge "30" ]; then
                  pass "$check"
                  pass "      * audit-log-maxage: $maxage"
              else
                  warn "$check"
                  warn "      * audit-log-maxage: $maxage"
              fi
          else
              warn "$check"
          fi
        remediation: |
          Edit the K3s config file /etc/rancher/k3s/config.yaml on the control plane node and set the audit-log-maxage parameter to 30 or as an appropriate number of days, for example,
          kube-apiserver-arg:
            - "audit-log-maxage=30"
      - id: K.1.2.19
        description: Ensure that the --audit-log-maxbackup argument is set to 10 or
          as appropriate (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--audit-log-maxbackup' >/dev/null 2>&1; then
              maxbackup=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--audit-log-maxbackup'|cut -d " " -f 1)
              if [ "$maxbackup" -ge "10" ]; then
                  pass "$check"
                  pass "      * audit-log-maxbackup: $maxbackup"
              else
                  warn "$check"
                  warn "      * audit-log-maxbackup: $maxbackup"
              fi
          else
              warn "$check"
          fi
        remediation: |
          Edit the K3s config file /etc/rancher/k3s/config.yaml on the control plane node and set the audit-log-maxbackup parameter to 10 or to an appropriate value. For example,
          kube-apiserver-arg:
            - "audit-log-maxbackup=10"
      - id: K.1.2.20
        description: Ensure that the --audit-log-maxsize argument is set to 100 or
          as appropriate (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--audit-log-maxsize' >/dev/null 2>&1; then
              maxsize=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--audit-log-maxsize'|cut -d " " -f 1)
              if [ "$maxsize" -ge "100" ]; then
                  pass "$check"
                  pass "      * audit-log-maxsize: $maxsize"
              else
                  warn "$check"
                  warn "      * audit-log-maxsize: $maxsize"
              fi
          else
              warn "$check"
          fi
        remediation: |
          Edit the K3s config file /etc/rancher/k3s/config.yaml on the control plane node and set the audit-log-maxsize parameter to an appropriate size in MB. For example,
          kube-apiserver-arg:
            - "audit-log-maxsize=100"
      - id: K.1.2.21
        description: Ensure that the --request-timeout argument is set as appropriate
          (Manual)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags: {}
        audit: |
          check="$id  - $description"
          pass "$check"
        remediation: |
          Permissive, per CIS guidelines, "it is recommended to set this limit as appropriate and change the default limit of 60 seconds only if needed". Edit the K3s config file /etc/rancher/k3s/config.yaml and set the below parameter if needed. For example,
          kube-apiserver-arg:
            - "request-timeout=300s"
      - id: K.1.2.22
        description: Ensure that the --service-account-lookup argument is set to true
          (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--service-account-lookup=true' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s does not set the --service-account-lookup argument. Edit the K3s config file /etc/rancher/k3s/config.yaml and set the service-account-lookup. For example,
          kube-apiserver-arg:
            - "service-account-lookup=true"
          Alternatively, you can delete the service-account-lookup parameter from this file so that the default takes effect.
      - id: K.1.2.23
        description: Ensure that the --service-account-key-file argument is set as
          appropriate (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--service-account-key-file' >/dev/null 2>&1; then
              file=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--service-account-key-file')
              file=$(append_prefix "$CONFIG_PREFIX" "$file")
              pass "$check"
              pass "      * service-account-key-file: $file"
          else
              warn "$check"
          fi
        remediation: |
          K3s automatically generates and sets the service account key file. It is located at /var/lib/rancher/k3s/server/tls/service.key. If this check fails, edit K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-apiserver-arg:
            - "service-account-key-file=<path>"
      - id: K.1.2.24
        description: Ensure that the --etcd-certfile and --etcd-keyfile arguments
          are set as appropriate (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--etcd-certfile' >/dev/null 2>&1; then
              if check_argument_from_journal "$KUBE_APISERVER_CMD" '--etcd-keyfile' >/dev/null 2>&1; then
                  certfile=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--etcd-certfile')
                  keyfile=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--etcd-keyfile')
                  certfile=$(append_prefix "$CONFIG_PREFIX" "$certfile")
                  keyfile=$(append_prefix "$CONFIG_PREFIX" "$keyfile")
                  pass "$check"
                  pass "      * etcd-certfile: $certfile"
                  pass "      * etcd-keyfile: $keyfile"
              else
                  warn "$check"
              fi
          else
              warn "$check"
          fi
        remediation: |
          K3s automatically generates and sets the etcd certificate and key files. They are located at /var/lib/rancher/k3s/server/tls/etcd/client.crt and /var/lib/rancher/k3s/server/tls/etcd/client.key. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-apiserver-arg:
            - "etcd-certfile=<path>"
            - "etcd-keyfile=<path>"
      - id: K.1.2.25
        description: Ensure that the --tls-cert-file and --tls-private-key-file arguments
          are set as appropriate (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--tls-cert-file' >/dev/null 2>&1; then
              if check_argument_from_journal "$KUBE_APISERVER_CMD" '--tls-private-key-file' >/dev/null 2>&1; then
                  certfile=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--tls-cert-file')
                  keyfile=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--tls-private-key-file')
                  certfile=$(append_prefix "$CONFIG_PREFIX" "$certfile")
                  keyfile=$(append_prefix "$CONFIG_PREFIX" "$keyfile")
                  pass "$check"
                  pass "      * tls-cert-file: $certfile"
                  pass "      * tls-private-key-file: $keyfile"
              else
                  warn "$check"
              fi
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s automatically generates and provides the TLS certificate and private key for the apiserver. They are generated and located at /var/lib/rancher/k3s/server/tls/serving-kube-apiserver.crt and /var/lib/rancher/k3s/server/tls/serving-kube-apiserver.key If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-apiserver-arg:
            - "tls-cert-file=<path>"
            - "tls-private-key-file=<path>"
      - id: K.1.2.26
        description: Ensure that the --client-ca-file argument is set as appropriate
          (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--client-ca-file' >/dev/null 2>&1; then
              cafile=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--client-ca-file')
              cafile=$(append_prefix "$CONFIG_PREFIX" "$cafile")
              pass "$check"
              pass "      * client-ca-file: $cafile"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s automatically provides the client certificate authority file. It is generated and located at /var/lib/rancher/k3s/server/tls/client-ca.crt. If for some reason you need to provide your own ca certificate, look at using the k3s certificate command line tool. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-apiserver-arg:
            - "client-ca-file=<path>"
      - id: K.1.2.27
        description: Ensure that the --etcd-cafile argument is set as appropriate
          (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--etcd-cafile' >/dev/null 2>&1; then
              cafile=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--etcd-cafile')
              cafile=$(append_prefix "$CONFIG_PREFIX" "$cafile")
              pass "$check"
              pass "      * etcd-cafile: $cafile"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s automatically provides the etcd certificate authority file. It is generated and located at /var/lib/rancher/k3s/server/tls/client-ca.crt. If for some reason you need to provide your own ca certificate, look at using the k3s certificate command line tool. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-apiserver-arg:
            - "etcd-cafile=<path>"
      - id: K.1.2.28
        description: Ensure that the --encryption-provider-config argument is set
          as appropriate (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--encryption-provider-config'| grep 'EncryptionConfig' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          K3s can be configured to use encryption providers to encrypt secrets at rest. Edit the K3s config file /etc/rancher/k3s/config.yaml on the control plane node and set the below parameter. secrets-encryption: true Secrets encryption can then be managed with the k3s secrets-encrypt command line tool. If needed, you can find the generated encryption config at /var/lib/rancher/k3s/server/cred/encryption-config.json.
      - id: K.1.2.29
        description: Ensure that encryption providers are appropriately configured
          (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--encryption-provider-config' >/dev/null 2>&1; then
              encryptionConfig=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--encryption-provider-config')
              if [ -f "$encryptionConfig" ]; then
                if [ $(grep -c "\- aescbc:\|\- kms:\|\- secretbox:" $encryptionConfig) -ne 0 ]; then
                  pass "$check"
                else
                  warn "$check"
                fi
              else
                warn "$check"
              fi
          else
              warn "$check"
          fi
        remediation: |
          K3s can be configured to use encryption providers to encrypt secrets at rest. K3s will utilize the aescbc provider. Edit the K3s config file /etc/rancher/k3s/config.yaml on the control plane node and set the below parameter. secrets-encryption: true Secrets encryption can then be managed with the k3s secrets-encrypt command line tool. If needed, you can find the generated encryption config at /var/lib/rancher/k3s/server/cred/encryption-config.json
      - id: K.1.2.30
        description: Ensure that the API Server only makes use of Strong Cryptographic
          Ciphers (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_APISERVER_CMD" '--tls-cipher-suites' >/dev/null 2>&1; then
              ciphers=$(get_argument_value_from_journal "$KUBE_APISERVER_CMD" '--tls-cipher-suites'|cut -d " " -f 1)
              found=$(echo $ciphers| sed -rn '/(TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256|TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256|TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305|TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384|TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305|TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384)/p')
              if [ ! -z "$found" ]; then
                pass "$check"
              else
                warn "$check"
              fi
          else
              warn "$check"
          fi
        remediation: |
          By default, the K3s kube-apiserver complies with this test. Changes to these values may cause regression, therefore ensure that all apiserver clients support the new TLS configuration before applying it in production deployments. If a custom TLS configuration is required, consider also creating a custom version of this rule that aligns with your requirements. If this check fails, remove any custom configuration around tls-cipher-suites or update the /etc/rancher/k3s/config.yaml file to match the default by adding the following:
          kube-apiserver-arg:
            - "tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305"
  - id: 1.3
    title: 1.3 - Controller Manager
    checks:
      - id: K.1.3.1
        description: Ensure that the --terminated-pod-gc-threshold argument is set
          as appropriate (Manual)
        type: master
        category: kubernetes
        scored: false
        profile: Level 1
        automated: false
        tags: {}
        audit: |
          check="$id  - $description"
          # Filter out processes like "/bin/tee -a /var/log/kube-controller-manager.log"
          # which exist on kops-managed clusters.
          if check_argument_from_journal "$KUBE_CONTROLLER_MANAGER_CMD" '--terminated-pod-gc-threshold' >/dev/null 2>&1; then
              threshold=$(get_argument_value_from_journal "$KUBE_CONTROLLER_MANAGER_CMD" '--terminated-pod-gc-threshold')
              pass "$check"
              pass "      * terminated-pod-gc-threshold: $threshold"
          else
              warn "$check"
          fi
        remediation: |
          Edit the K3s config file /etc/rancher/k3s/config.yaml on the control plane node and set the --terminated-pod-gc-threshold to an appropriate threshold,
          kube-controller-manager-arg:
            - "terminated-pod-gc-threshold=10"
      - id: K.1.3.2
        description: Ensure that the --profiling argument is set to false (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags: {}
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_CONTROLLER_MANAGER_CMD" '--profiling=false' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s sets the --profiling argument to false. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-controller-manager-arg:
            - "profiling=true"
      - id: K.1.3.3
        description: Ensure that the --use-service-account-credentials argument is
          set to true (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_CONTROLLER_MANAGER_CMD" '--use-service-account-credentials=true' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s sets the --use-service-account-credentials argument to true. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-controller-manager-arg:
            - "use-service-account-credentials=false"
      - id: K.1.3.4
        description: Ensure that the --service-account-private-key-file argument is
          set as appropriate (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_CONTROLLER_MANAGER_CMD" '--service-account-private-key-file' >/dev/null 2>&1; then
              keyfile=$(get_argument_value_from_journal "$KUBE_CONTROLLER_MANAGER_CMD" '--service-account-private-key-file')
              keyfile=$(append_prefix "$CONFIG_PREFIX" "$keyfile")
              pass "$check"
              pass "      * service-account-private-key-file: $keyfile"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s automatically provides the service account private key file. It is generated and located at /var/lib/rancher/k3s/server/tls/service.current.key. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-controller-manager-arg:
            - "service-account-private-key-file=<path>"
      - id: K.1.3.5
        description: Ensure that the --root-ca-file argument is set as appropriate
          (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_CONTROLLER_MANAGER_CMD" '--root-ca-file' >/dev/null 2>&1; then
              cafile=$(get_argument_value_from_journal "$KUBE_CONTROLLER_MANAGER_CMD" '--root-ca-file')
              cafile=$(append_prefix "$CONFIG_PREFIX" "$cafile")
              pass "$check"
              pass "      * root-ca-file: $cafile"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s automatically provides the root CA file. It is generated and located at /var/lib/rancher/k3s/server/tls/server-ca.crt. If for some reason you need to provide your own ca certificate, look at using the k3s certificate command line tool. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-controller-manager-arg:
            - "root-ca-file=<path>"
      - id: K.1.3.6
        description: Ensure that the RotateKubeletServerCertificate argument is set
          to true (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 2
        automated: true
        tags:
          HIPAA: []
          PCI: []
          GDPR: []
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_CONTROLLER_MANAGER_CMD" '--feature-gates' >/dev/null 2>&1; then
              serverCert=$(get_argument_value_from_journal "$KUBE_CONTROLLER_MANAGER_CMD" '--feature-gates')
              found=$(echo $serverCert| grep 'RotateKubeletServerCertificate=true')
              if [ ! -z $found ]; then
                pass "$check"
              else
                warn "$check"
              fi
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s does not set the RotateKubeletServerCertificate feature gate. If you have enabled this feature gate, you should remove it. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml, remove any lines like below.
          kube-controller-manager-arg:
            - "feature-gate=RotateKubeletServerCertificate"
      - id: K.1.3.7
        description: Ensure that the --bind-address argument is set to 127.0.0.1 (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags: {}
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_CONTROLLER_MANAGER_CMD" '--bind-address'| grep '127.0.0.1' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s sets the --bind-address argument to 127.0.0.1 If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-controller-manager-arg:
            - "bind-address=<IP>"
  - id: 1.4
    title: 1.4 - Scheduler
    checks:
      - id: K.1.4.1
        description: Ensure that the --profiling argument is set to false (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags: {}
        audit: |
          check="$id  - $description"
          if check_argument_from_journal "$KUBE_SCHEDULER_CMD" '--profiling=false' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s sets the --profiling argument to false. If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-scheduler-arg:
            - "profiling=true"
      - id: K.1.4.2
        description: Ensure that the --bind-address argument is set to 127.0.0.1 (Automated)
        type: master
        category: kubernetes
        scored: true
        profile: Level 1
        automated: true
        tags: {}
        audit: |
          check="$id  - $description"
          if get_argument_value_from_journal "$KUBE_SCHEDULER_CMD" '--bind-address'| grep '127.0.0.1' >/dev/null 2>&1; then
              pass "$check"
          else
              warn "$check"
          fi
        remediation: |
          By default, K3s sets the --bind-address argument to 127.0.0.1 If this check fails, edit the K3s config file /etc/rancher/k3s/config.yaml and remove any lines like below.
          kube-scheduler-arg:
            - "bind-address=<IP>"
